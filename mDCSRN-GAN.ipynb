{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d499c44f89489d8722c8e0e3bb4d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='path')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "file_path = widgets.Text(\n",
    "    description = 'path'\n",
    ")\n",
    "\n",
    "\n",
    "display(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(file_path.value)\n",
    "\n",
    "num_unit = int(config['NN']['n_u'])\n",
    "num_block = int(config['NN']['n_block'])\n",
    "growth = int(config['NN']['growth'])\n",
    "\n",
    "lr = float(config['NN']['lr'])\n",
    "beta1 = float(config['NN']['beta1'])\n",
    "alpha = float(config['NN']['alpha'])\n",
    "\n",
    "im_size = int(config['Training']['im_size'])\n",
    "n_epoch = int(config['Training']['n_epoch'])\n",
    "BATCH_SIZE = int(config['Training']['BATCH_SIZE'])\n",
    "hr_path = config['Training']['hr_path']\n",
    "lr_path = config['Training']['lr_path']\n",
    "lr_path_test = config['Training']['lr_test_data']\n",
    "hr_path_test = config['Training']['hr_test_data']\n",
    "log_name = config['Training']['log']\n",
    "checkpoint_dir = config['Training']['checkpoint_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class ctimage(Dataset):\n",
    "    def __init__(self, img_hr, img_lr):\n",
    "        self.img_hr = img_hr\n",
    "        self.img_lr = img_lr\n",
    "    def __len__(self):\n",
    "        return self.img_hr.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        hr_img = torch.from_numpy(np.expand_dims(self.img_hr[idx],axis = 0))\n",
    "        lr_img = torch.from_numpy(np.expand_dims(self.img_lr[idx],axis = 0))\n",
    "        return hr_img,lr_img\n",
    "\n",
    "hr_file = h5py.File(hr_path, 'r')\n",
    "lr_file = h5py.File(lr_path, 'r')\n",
    "\n",
    "t_hr_file = h5py.File(hr_path_test, 'r')\n",
    "t_lr_file = h5py.File(lr_path_test, 'r')\n",
    "\n",
    "training_data = ctimage(hr_file['data'],lr_file['data'])\n",
    "test_data = ctimage(t_hr_file['data'],t_lr_file['data'])\n",
    "\n",
    "dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "  (lrelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (block1): DiscriminatorBlock(\n",
       "    (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (ada): AdaptiveAvgPool3d(output_size=1)\n",
       "  (Dense1): Conv3d(64, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (lrelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (Dense2): Conv3d(512, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import DenseNet as dn\n",
    "from torch import nn\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv3d:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif type(m) == nn.BatchNorm3d:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)        \n",
    "\n",
    "netG = dn.Generator(num_unit,num_block)#fill input\n",
    "netD = dn.Discriminator()\n",
    "\n",
    "netG.apply(init_weights)\n",
    "netD.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "gen_loss = dn.GeneratorLoss()\n",
    "\n",
    "if(torch.cuda.device_count()>1):\n",
    "    netG = nn.DataParallel(netG)\n",
    "    netD = nn.DataParallel(netD)\n",
    "    criterion = criterion.cuda()\n",
    "    gen_loss = gen_loss.cuda()\n",
    "    \n",
    "    netG = netG.cuda()\n",
    "    netD = netD.cuda()\n",
    "elif(torch.cuda.is_available()):\n",
    "    netG = netG.cuda()\n",
    "    netD = netD.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    gen_loss = gen_loss.cuda()\n",
    "\n",
    "d_optimizer = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "g_optimizer = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "\n",
    "d_schedule = optim.lr_scheduler.StepLR(d_optimizer, step_size=500, gamma=0.1)\n",
    "g_schedule = optim.lr_scheduler.StepLR(g_optimizer, step_size=500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/msam-server/Documents/DeepLearning_marc/deep_learning_pm/DenseNet.py\", line 112, in forward\n    out = self.lrelu1(self.conv1(x))\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 535, in forward\n    return F.leaky_relu(input, self.negative_slope, self.inplace)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py\", line 1062, in leaky_relu\n    result = torch._C._nn.leaky_relu(input, negative_slope)\nRuntimeError: CUDA out of memory. Tried to allocate 1.91 GiB (GPU 0; 3.94 GiB total capacity; 2.07 GiB already allocated; 1.22 GiB free; 921.50 KiB cached)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8c788dab40c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#train with real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/msam-server/Documents/DeepLearning_marc/deep_learning_pm/DenseNet.py\", line 112, in forward\n    out = self.lrelu1(self.conv1(x))\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/activation.py\", line 535, in forward\n    return F.leaky_relu(input, self.negative_slope, self.inplace)\n  File \"/home/msam-server/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py\", line 1062, in leaky_relu\n    result = torch._C._nn.leaky_relu(input, negative_slope)\nRuntimeError: CUDA out of memory. Tried to allocate 1.91 GiB (GPU 0; 3.94 GiB total capacity; 2.07 GiB already allocated; 1.22 GiB free; 921.50 KiB cached)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import tensor\n",
    "import torchvision\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(comment=log_name)\n",
    "\n",
    "gen_iterations = 0\n",
    "for epoch in tqdm(range(n_epoch)):\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        netD.train()\n",
    "        netG.train()\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        \n",
    "        hr_img = sample_batched[0].float().cuda()\n",
    "        lr_img = sample_batched[1].float().cuda()\n",
    "        \n",
    "        real_label = tensor([0.9]*BATCH_SIZE, dtype = torch.float).cuda()  \n",
    "        \n",
    "        #train with real\n",
    "        output = netD(hr_img)\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward()\n",
    "        \n",
    "        fake = netG(lr_img)\n",
    "        \n",
    "        output = netD(fake.detach())\n",
    "        \n",
    "        fake_label = tensor([0.0]*BATCH_SIZE, dtype = torch.float).cuda()\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        \n",
    "        d_optimizer.step()\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        real_label = tensor([1.0]*BATCH_SIZE, dtype = torch.float).cuda() # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = gen_loss(output, real_label, fake, hr_img)\n",
    "        errG.backward()\n",
    "\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Loss/d',errD.item(),gen_iterations)\n",
    "        writer.add_scalar('Loss/g',errG.item(),gen_iterations)\n",
    "        \n",
    "        gen_iterations += 1\n",
    "        \n",
    "    work_dir = \"training_checkpoints\"\n",
    "    d_schedule.step()\n",
    "    g_schedule.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        if(torch.cuda.device_count()>1):\n",
    "            G_Data = netG.module.state_dict()\n",
    "            D_Data = netD.module.state_dict()\n",
    "        else:\n",
    "            G_Data = netG.state_dict()\n",
    "            D_Data = netD.state_dict()\n",
    "        torch.save(G_Data, os.path.join(\".\",work_dir,checkpoint_dir,\"netG_epoch_{}.pth\".format(epoch)))\n",
    "        torch.save(D_Data, os.path.join(\".\",work_dir,checkpoint_dir,\"netD_epoch_{}.pth\".format(epoch)))\n",
    "        \n",
    "        netD.eval()\n",
    "        netG.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "                hr_img_t = sample_batched[0].float().to(device_1)\n",
    "                lr_img_t = sample_batched[1].float().to(device_0)\n",
    "                \n",
    "                result_img = netG(lr_img_t)\n",
    "                output = netD(result_img)\n",
    "                errT = gen_loss(output,real_label,result_img,hr_img_t)\n",
    "                img_grid = torchvision.utils.make_grid(result_img[:,:,:,:,10])\n",
    "                \n",
    "                writer.add_images('test output', img_grid, epoch)\n",
    "            \n",
    "                writer.add_scalar('Loss/g_test', errT.item(), epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_file.close()\n",
    "lr_file.close()\n",
    "\n",
    "t_hr_file.close()\n",
    "t_lr_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
