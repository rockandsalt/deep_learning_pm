{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecba7b988f745238d692fa390b07cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='path')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "file_path = widgets.Text(\n",
    "    description = 'path'\n",
    ")\n",
    "\n",
    "\n",
    "display(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(file_path.value)\n",
    "\n",
    "nz = int(config['NN']['nz'])\n",
    "ngf = int(config['NN']['ngf'])\n",
    "ndf = int(config['NN']['ndf'])\n",
    "lr = float(config['NN']['lr'])\n",
    "beta1 = float(config['NN']['beta1'])\n",
    "\n",
    "im_size = int(config['Training']['im_size'])\n",
    "n_epoch = int(config['Training']['n_epoch'])\n",
    "BATCH_SIZE = int(config['Training']['BATCH_SIZE'])\n",
    "Ti_path = config['Training']['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class ctimage(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.img = h5py.File(path, 'r')['data']\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        #one sided label smoothing\n",
    "        return torch.from_numpy(np.expand_dims(self.img[idx],axis = 0)), 0.9\n",
    "\n",
    "training_data = ctimage(Ti_path)\n",
    "\n",
    "dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv3d(1, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (3): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (6): Conv3d(32, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (7): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (9): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "  (10): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (12): Conv3d(128, 1, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "  (13): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dcgan\n",
    "from torch import nn\n",
    "nc = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv3d:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif type(m) == nn.BatchNorm3d:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)        \n",
    "\n",
    "netG = dcgan.make_generator_model(im_size, nz, nc, ngf)\n",
    "netD = dcgan.make_discriminator_model(im_size, nc, ndf)\n",
    "\n",
    "netG.apply(init_weights)\n",
    "netD.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if(torch.cuda.device_count()>1):\n",
    "    netG = nn.DataParallel(netG)\n",
    "    netD = nn.DataParallel(netD)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    netG = netG.to(device)\n",
    "    netD = netD.to(device)\n",
    "elif(torch.cuda.is_available()):\n",
    "    netG = netG.to(device)\n",
    "    netD = netD.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "d_optimizer = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "g_optimizer = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, 0.999))\n",
    "\n",
    "d_schedule = optim.lr_scheduler.StepLR(d_optimizer, step_size=500, gamma=0.1)\n",
    "g_schedule = optim.lr_scheduler.StepLR(g_optimizer, step_size=500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/egwheat/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/egwheat/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import tensor\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "training_curve = \"training_curve\"\n",
    "\n",
    "num_iteration = len(dataloader)*n_epoch\n",
    "\n",
    "hf = h5py.File(os.path.join('.',training_curve,'training_curve.hdf5'), \"w\")\n",
    "loss_d = hf.create_dataset(\"Loss D\", (num_iteration,), dtype='f')\n",
    "loss_g = hf.create_dataset(\"Loss G\", (num_iteration,), dtype='f')\n",
    "d_x = hf.create_dataset(\"D(x)\", (num_iteration,), dtype='f')\n",
    "d_g_z = hf.create_dataset(\"D(G(z))\", (num_iteration,2), dtype='f')\n",
    "\n",
    "gen_iterations = 0\n",
    "for epoch in tqdm(range(n_epoch)):\n",
    "    start = time.time()\n",
    "    d_schedule.step()\n",
    "    g_schedule .step()\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        real_img = sample_batched[0].to(device, dtype=torch.float)\n",
    "        real_label = sample_batched[1].to(device, dtype=torch.float)        \n",
    "        \n",
    "        #train with real\n",
    "        output = netD(real_img)\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "        \n",
    "        noise = torch.rand((BATCH_SIZE,nz,1,1,1)).to(device, dtype=torch.float)\n",
    "        fake = netG(noise).detach()\n",
    "        \n",
    "        output = netD(fake)\n",
    "        \n",
    "        fake_label = tensor([0.0]*BATCH_SIZE, dtype = torch.float).to(device)\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        g_iter = 1\n",
    "        \n",
    "        while g_iter != 0:\n",
    "            netG.zero_grad()\n",
    "            real_label = tensor([1.0]*BATCH_SIZE, dtype = torch.float).to(device) # fake labels are real for generator cost\n",
    "            noise = torch.ones(())\n",
    "            noise = noise.new_empty((BATCH_SIZE,nz,1,1,1), dtype=torch.float, device=device)\n",
    "            noise.normal_(0,1)\n",
    "            fake = netG(noise)\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, real_label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.data.mean()\n",
    "            g_optimizer.step()\n",
    "            g_iter -= 1\n",
    "        \n",
    "        loss_d[gen_iterations] = errD.data.item()\n",
    "        loss_g[gen_iterations] = errG.data.item()\n",
    "        d_x[gen_iterations] = D_x.cpu()\n",
    "        d_g_z[gen_iterations][0] = D_G_z1\n",
    "        d_g_z[gen_iterations][1] = D_G_z2\n",
    "        \n",
    "        gen_iterations += 1\n",
    "        \n",
    "    work_dir = \"training_checkpoints\"\n",
    "    if epoch % 20 == 0:\n",
    "        if(torch.cuda.device_count()>1):\n",
    "            G_Data = netG.module.state_dict()\n",
    "            D_Data = netD.module.state_dict()\n",
    "        else:\n",
    "            G_Data = netG.state_dict()\n",
    "            D_Data = netD.state_dict()\n",
    "        torch.save(G_Data, os.path.join(\".\",work_dir,\"netG_epoch_{}.pth\".format(epoch)))\n",
    "        torch.save(D_Data, os.path.join(\".\",work_dir,\"netD_epoch_{}.pth\".format(epoch)))\n",
    "        hf.flush()\n",
    "\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
