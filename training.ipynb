{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb94a30092d4bb38ef35b97a97618d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=512, description='nz'), IntText(value=32, description='ngf'), IntT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# size of latent z vector\n",
    "nz = widgets.IntText(\n",
    "    value=512,\n",
    "    description='nz'\n",
    ")\n",
    "\n",
    "ngf =  widgets.IntText(\n",
    "    value=32,\n",
    "    description='ngf'\n",
    ")\n",
    "\n",
    "ndf =  widgets.IntText(\n",
    "    value=16,\n",
    "    description='ndf'\n",
    ")\n",
    "\n",
    "n_epoch = widgets.IntText(\n",
    "    value=25,\n",
    "    description='n epoch'\n",
    ")\n",
    "\n",
    "lr = widgets.FloatText(\n",
    "    value = 0.002,\n",
    "    description = 'learning rate'\n",
    ")\n",
    "\n",
    "beta1 = widgets.FloatText(\n",
    "    value = 0.5,\n",
    "    description = 'beta 1'\n",
    ")\n",
    "\n",
    "im_size = widgets.IntText(\n",
    "    value = 64,\n",
    "    description = 'im size'\n",
    ")\n",
    "\n",
    "file_path = widgets.Text(\n",
    "    description = 'path'\n",
    ")\n",
    "\n",
    "u_box = widgets.HBox([nz, ngf, ndf, n_epoch])\n",
    "b_box = widgets.HBox([lr, beta1,im_size])\n",
    "v_b = widgets.VBox([u_box,b_box,file_path])\n",
    "\n",
    "display(v_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "class ctimage(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.img = h5py.File(path, 'r')['data']\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.from_numpy(np.expand_dims(self.img[idx],axis = 0)), 0.9\n",
    "\n",
    "training_data = ctimage(file_path.value)\n",
    "\n",
    "dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcgan\n",
    "nc = 1\n",
    "\n",
    "netG = dcgan.make_generator_model(im_size.value, nz.value, nc, ngf.value)\n",
    "netD = dcgan.make_discriminator_model(im_size.value, nc, ndf.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    netG = netG.cuda()\n",
    "    netD = netD.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "d_optimizer = optim.Adam(netD.parameters(), lr = lr.value, betas = (beta1.value, 0.999))\n",
    "g_optimizer = optim.Adam(netG.parameters(), lr = lr.value, betas = (beta1.value, 0.999))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/home/msam44/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/msam44/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████| 125/125 [5:57:23<00:00, 171.77s/it]  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import tensor\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "training_curve = \"training_curve\"\n",
    "\n",
    "num_iteration = len(dataloader)*n_epoch.value\n",
    "\n",
    "hf = h5py.File(os.path.join('.',training_curve,'training_curve.hdf5'), \"w\")\n",
    "loss_d = hf.create_dataset(\"Loss D\", (num_iteration,), dtype='f')\n",
    "loss_g = hf.create_dataset(\"Loss G\", (num_iteration,), dtype='f')\n",
    "d_x = hf.create_dataset(\"D(x)\", (num_iteration,), dtype='f')\n",
    "d_g_z = hf.create_dataset(\"D(G(z))\", (num_iteration,2), dtype='f')\n",
    "\n",
    "gen_iterations = 0\n",
    "for epoch in tqdm(range(n_epoch.value)):\n",
    "    start = time.time()\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        real_img = sample_batched[0].to(device, dtype=torch.float)\n",
    "        real_label = sample_batched[1].to(device, dtype=torch.float)        \n",
    "        \n",
    "        #train with real\n",
    "        output = netD(real_img)\n",
    "        errD_real = criterion(output, real_label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "        \n",
    "        noise = torch.rand((BATCH_SIZE,nz.value,1,1,1)).to(device, dtype=torch.float)\n",
    "        fake = netG(noise).detach()\n",
    "        \n",
    "        output = netD(fake)\n",
    "        \n",
    "        fake_label = tensor([0.0]*BATCH_SIZE, dtype = torch.float).to(device)\n",
    "        errD_fake = criterion(output, fake_label)\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        g_iter = 1\n",
    "        \n",
    "        while g_iter != 0:\n",
    "            netG.zero_grad()\n",
    "            real_label = tensor([1.0]*BATCH_SIZE, dtype = torch.float).to(device) # fake labels are real for generator cost\n",
    "            noise = torch.rand((BATCH_SIZE,nz.value,1,1,1)).to(device, dtype=torch.float)\n",
    "            \n",
    "            fake = netG(noise)\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, real_label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.data.mean()\n",
    "            g_optimizer.step()\n",
    "            g_iter -= 1\n",
    "        \n",
    "        loss_d[gen_iterations] = errD.data.item()\n",
    "        loss_g[gen_iterations] = errG.data.item()\n",
    "        d_x[gen_iterations] = D_x.cpu()\n",
    "        d_g_z[gen_iterations][0] = D_G_z1\n",
    "        d_g_z[gen_iterations][1] = D_G_z2\n",
    "        \n",
    "        gen_iterations += 1\n",
    "        \n",
    "    work_dir = \"training_checkpoints\"\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(netG.state_dict(), os.path.join(\".\",work_dir,\"netG_epoch_{}.pth\".format(epoch)))\n",
    "        torch.save(netD.state_dict(), os.path.join(\".\",work_dir,\"netD_epoch_{}.pth\".format(epoch)))\n",
    "        hf.flush()\n",
    "\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
